<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>
  <groupId>com.newco.dataflow</groupId>
  <artifactId>df</artifactId>
  <version>0.0.1-SNAPSHOT</version>
  <packaging>jar</packaging>
  <name>newco</name>
  <url></url>
  <properties>
    <timestamp>${maven.build.timestamp}</timestamp>
    <maven.build.timestamp.format>yyyy-MM-dd-HH-mm</maven.build.timestamp.format>

    <gcp.project>SET_YOUR_PROJECT_ID</gcp.project>
    <gcp.stagingLocation>gs://SET_YOUR_BUCKET_NAME_HERE/staging</gcp.stagingLocation>
    <df.jobName>newco-flow-${timestamp}</df.jobName>
    <df.jobFile>gs://SET_YOUR_BUCKET_NAME_HERE/common/templates/out.json</df.jobFile>
    <df.workerMachineType></df.workerMachineType>
    <df.numWorkers>20</df.numWorkers>
    <df.workerDiskSize>50</df.workerDiskSize>
    <df.bqDest>DFPAllClients.LineItem</df.bqDest>
    <df.gsc>gs://SET_YOUR_BUCKET_NAME_HERE/temp/</df.gsc>
    <df.scalingAlgorithm>BASIC</df.scalingAlgorithm>
    <df.input>gs://SET_YOUR_BUCKET_NAME_HERE/input/lineitem.csv</df.input>
    <df.outputFile></df.outputFile>
    <df.outputTable>${gcp.project}:${df.bqDest}</df.outputTable>
 
    <slf4j.version>1.7.7</slf4j.version>
    <logback-classic.version>1.0.1</logback-classic.version>
    <junit.version>4.13.1</junit.version>
    <hamcrest.version>1.3</hamcrest.version>
    <mockito-all.version>1.10.19</mockito-all.version>
    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
    <maven.compiler.source>1.8</maven.compiler.source>
    <maven.compiler.target>1.8</maven.compiler.target>
  </properties>
   
  <dependencyManagement>
    <dependencies>
	    <dependency>
		    <groupId>gcp-df</groupId>
		    <artifactId>google-cloud-dataflow-java-sdk-all</artifactId>
		    <version>1.9.0</version>
	   </dependency>
      <dependency>
        <groupId>com.google.cloud.dataflow</groupId>
        <artifactId>google-cloud-dataflow-java-sdk-all</artifactId>
        <version>[1.9.9]</version>
      </dependency>
      <dependency>
        <groupId>org.slf4j</groupId>
        <artifactId>slf4j-api</artifactId>
        <version>${slf4j.version}</version>
      </dependency>
      <dependency>
        <groupId>ch.qos.logback</groupId>
        <artifactId>logback-classic</artifactId>
        <version>${logback-classic.version}</version>
      </dependency>
      <dependency>
        <groupId>junit</groupId>
        <artifactId>junit</artifactId>
        <version>${junit.version}</version>
        <scope>test</scope>
      </dependency>
      <dependency>
        <groupId>org.mockito</groupId>
        <artifactId>mockito-all</artifactId>
        <version>${mockito-all.version}</version>
        <scope>test</scope>
      </dependency>
      <dependency>
        <groupId>org.hamcrest</groupId>
        <artifactId>hamcrest-library</artifactId>
        <version>${hamcrest.version}</version>
        <scope>test</scope>
      </dependency>
    </dependencies>
  </dependencyManagement>
  
  <dependencies>
    <dependency>
    <groupId>com.google.guava</groupId>
    <artifactId>guava</artifactId>
    <version>30.1-jre</version>
    </dependency>
 	<dependency>
	    <groupId>com.google.cloud.dataflow</groupId>
	    <artifactId>google-cloud-dataflow-java-sdk-all</artifactId>
	    <version>1.9.0</version>
	</dependency>
    <dependency>
      <groupId>org.slf4j</groupId>
      <artifactId>slf4j-api</artifactId>
    </dependency>
    <dependency>
      <groupId>ch.qos.logback</groupId>
      <artifactId>logback-classic</artifactId>
    </dependency>
    <dependency>
      <groupId>junit</groupId>
      <artifactId>junit</artifactId>
    </dependency>
    <dependency>
      <groupId>org.mockito</groupId>
      <artifactId>mockito-all</artifactId>
    </dependency>
    <dependency>
      <groupId>org.hamcrest</groupId>
      <artifactId>hamcrest-library</artifactId>
    </dependency>
 </dependencies>
 
   <build>
    <plugins>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-shade-plugin</artifactId>
        <version>1.6</version>
        <configuration>
          <createDependencyReducedPom>true</createDependencyReducedPom>
          <filters>
            <filter>
              <artifact>*:*</artifact>
              <excludes>
                <exclude>META-INF/*.SF</exclude>
                <exclude>META-INF/*.DSA</exclude>
                <exclude>META-INF/*.RSA</exclude>
              </excludes>
            </filter>
          </filters>
          <finalName>uber-${artifactId}-${version}</finalName>
        </configuration>
        <executions>
           <execution>
           <id>shade</id>
              <phase>package</phase>
              <goals>
                  <goal>shade</goal>
              </goals>
              <configuration>
                  <artifactSet>
                      <includes>
                         <include>com.google.cloud.dataflow.sdk</include>
                      </includes>
                  </artifactSet>
              </configuration>
          </execution>        
          <execution>
          <id>shade-main</id>
            <phase>package</phase>
            <goals>
              <goal>shade</goal>
            </goals>
            <configuration>
              <artifactSet>
                <!-- include any jar that would normally be in the containers lib -->
                <excludes>
                  <!-- <exclude>org.apache.storm:*</exclude> -->
                  <exclude>io.netty:*</exclude>
                  <exclude>org.objenesis:*</exclude>
                  <exclude>com.esotericsoftware.reflectasm:reflectasm</exclude>
                  <exclude>com.esotericsoftware:reflectasm</exclude>
                  <exclude>com.esotericsoftware.minlog:minlog</exclude>
                  <exclude>org.mortbay.jetty:*</exclude>
                </excludes>
              </artifactSet>
              <transformers>
                <transformer implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer" />
                <transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer">
                  <mainClass>com.newco.dataflow.pipeline.LineItemTransformPipeline</mainClass>
                </transformer>
              </transformers>
            </configuration>
          </execution>
        </executions>
      </plugin>
    </plugins>
   </build>
  
  <profiles>
    <profile>
      <id>local</id>
      <build>
        <plugins>
          <plugin>
            <groupId>org.codehaus.mojo</groupId>
            <artifactId>exec-maven-plugin</artifactId>
            <version>1.2</version>
	        <executions>
	          <execution>
	                <id>default-cli</id>
	                <goals>
	                  <goal>exec</goal>
	                </goals>
		            <configuration>
		              <executable>java</executable>
		              <arguments>
		                <argument>-jar</argument>
		                <argument>/target/df-${version}-SNAPSHOT.jar</argument>
		                <argument>--runner=DirectPipelineRunner</argument>
		                <argument>--project=${gcp.project}</argument>
		                <argument>--stagingLocation=${gcp.stagingLocation}</argument>
		                <argument>--jobName=${df.jobName}</argument>
		                <argument>--dataflowJobFile=${df.jobFile}</argument>
		                <argument>--autoscalingAlgorithm=${df.scalingAlgorithm}</argument>
		                <argument>--workerMachineType=${df.workerMachineType}</argument>
		                <argument>--diskSizeGb=${df.workerDiskSize}</argument>
		                <argument>--numWorkers=${df.numWorkers}</argument>
		                <argument>--inputFilePath=${df.input}</argument>
		                <argument>--outputFilePath=${df.outputFile}</argument>
		              </arguments>
		            </configuration>
                    </execution>
        	</executions>
          </plugin>
        </plugins>
      </build>
    </profile>
    <profile>
     <id>gcp</id>
     <build>
     <plugins>
	 <plugin>
		<groupId>org.codehaus.mojo</groupId>
		<artifactId>exec-maven-plugin</artifactId>
		<version>1.2</version>
		<executions>
		  <execution>
				<id>default-cli</id>
				<goals>
				  <goal>exec</goal>
				</goals>	        
				<configuration>
				  <executable>java</executable>
				  <mainClass>com.newco.dataflow.pipeline.LineItemTransformPipeline</mainClass>
				  <arguments>
					<argument>-jar</argument>
					<argument>/target/uber-${artifactId}-${version}.jar</argument>
					<argument>--runner=BlockingDataflowPipelineRunner</argument>
					<argument>--project=${gcp.project}</argument>
					<argument>--stagingLocation=${gcp.stagingLocation}</argument>
					<argument>--jobName=${df.jobName}</argument>
					<argument>--dataflowJobFile=${df.jobFile}</argument>
					<argument>--autoscalingAlgorithm=${df.scalingAlgorithm}</argument>
					<argument>--workerMachineType=${df.workerMachineType}</argument>
					<argument>--diskSizeGb=${df.workerDiskSize}</argument>
					<argument>--numWorkers=${df.numWorkers}</argument>
					<argument>--inputFilePath=${df.input}</argument>
					<argument>--outputTable=${df.outputTable}</argument>
				  </arguments>
				</configuration>
		   </execution>
		</executions>
	</plugin>     
	
	<plugin>
		<artifactId>maven-assembly-plugin</artifactId>
		<configuration>
			<descriptorRefs>
				<descriptorRef>jar-with-dependencies</descriptorRef>
			</descriptorRefs>
			<archive>
				<manifest>
					<mainClass>com.newco.dataflow.pipeline.LineItemTransformPipeline</mainClass>
				</manifest>
			</archive>
		</configuration>
		<executions>
			<execution>
				<phase>package</phase> <!-- bind to the packaging phase -->
				<goals>
					<goal>single</goal>
				</goals>
			</execution>
		</executions>
	</plugin>
    </plugins>
    </build>
    </profile>
  </profiles>
</project>
